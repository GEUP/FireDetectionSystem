{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7323,
     "status": "ok",
     "timestamp": 1622380122125,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "S2zV70MfJ2Z6"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL96Iha8J2Z8"
   },
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(columns=['key','common train data len','fire train data len','smoke train data len', \n",
    "                          'common validation data len','fire validation data len','smoke validation data len',\n",
    "                          'EPOCHS',\n",
    "                          'learning_rate_schedule',\n",
    "                          'batch size',\n",
    "                          'loss_func',\n",
    "                          'optimizer',\n",
    "                          'comment',\n",
    "                          'test_accuracy',\n",
    "                          'train time'\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./result/HyperParameter.csv',encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1622380122137,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "apuPEzPAJ2Z9"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# mount google drive \\nfrom google.colab import drive\\n\\ndrive.mount(\\'/content/gdrive/\\')\\ncur_dir = os.path.join(cur_dir,\"/content/gdrive/MyDrive/fire detection\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# mount google drive \n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/')\n",
    "cur_dir = os.path.join(cur_dir,\"/content/gdrive/MyDrive/fire detection\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1622380122138,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "2awKliL-J2Z-",
    "outputId": "5c38f425-dc85-444d-bfd2-ad322d76c3e0"
   },
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "data_dir = os.path.join(cur_dir,'data')\n",
    "camera_dir = os.path.join(data_dir,'crawled_images')\n",
    "camera0_dir = os.path.join(camera_dir,'0')\n",
    "camera1_dir = os.path.join(camera_dir,'1')\n",
    "camera2_dir = os.path.join(camera_dir,'2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'normal_img_files = os.listdir(camera0_dir)\\nfire_img_files = os.listdir(camera1_dir)\\nsmoke_img_files = os.listdir(camera2_dir)\\nprint(len(normal_img_files), len(fire_img_files), len(smoke_img_files))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''normal_img_files = os.listdir(camera0_dir)\n",
    "fire_img_files = os.listdir(camera1_dir)\n",
    "smoke_img_files = os.listdir(camera2_dir)\n",
    "print(len(normal_img_files), len(fire_img_files), len(smoke_img_files))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 16394,
     "status": "ok",
     "timestamp": 1622380138515,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "keBXoWshJ2Z_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tfr_dir = os.path.join(camera_dir,'tfrecord')\\nos.makedirs(tfr_dir, exist_ok=True)\\n\\ntrain_tfr_dir = os.path.join(tfr_dir,'train.tfr')\\nval_tfr_dir = os.path.join(tfr_dir,'val.tfr')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tfr_dir = os.path.join(camera_dir,'tfrecord')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "train_tfr_dir = os.path.join(tfr_dir,'train.tfr')\n",
    "val_tfr_dir = os.path.join(tfr_dir,'val.tfr')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_dir = os.path.join(camera_dir,'tfrecord-before augmentation')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "train_tfr_dir = os.path.join(tfr_dir,'train.tfr')\n",
    "val_tfr_dir = os.path.join(tfr_dir,'val.tfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_N_TRAIN = 3900\n",
    "N_N_VAL = 1301\n",
    "\n",
    "N_F_TRAIN = 1608\n",
    "N_F_VAL = 537\n",
    "\n",
    "N_S_TRAIN = 768\n",
    "N_S_VAL = 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N_N_TRAIN = 3 * (len(normal_img_files) // 4)\\nN_N_VAL = len(normal_img_files) - N_N_TRAIN\\n\\nN_F_TRAIN = 3 * (len(fire_img_files) // 4)\\nN_F_VAL = len(fire_img_files) - N_F_TRAIN\\n\\nN_S_TRAIN = 3 * (len(smoke_img_files) // 4)\\nN_S_VAL = len(smoke_img_files) - N_S_TRAIN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''N_N_TRAIN = 3 * (len(normal_img_files) // 4)\n",
    "N_N_VAL = len(normal_img_files) - N_N_TRAIN\n",
    "\n",
    "N_F_TRAIN = 3 * (len(fire_img_files) // 4)\n",
    "N_F_VAL = len(fire_img_files) - N_F_TRAIN\n",
    "\n",
    "N_S_TRAIN = 3 * (len(smoke_img_files) // 4)\n",
    "N_S_VAL = len(smoke_img_files) - N_S_TRAIN'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1622380138517,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "v9u1DJvcJ2aA",
    "outputId": "d4c2ec58-96cd-415a-e716-a6b8ae19c72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#학습 데이터를 용량이 적은 RAM 대신에 디스크에서 필요한 만큼 불러가면서 학습하기 위해 tfrecord를 사용함\\n#학습 데이터 디스크에 저장 \\n\\ntrain_tfr_writer = tf.io.TFRecordWriter(train_tfr_dir)\\nval_tfr_writer = tf.io.TFRecordWriter(val_tfr_dir)\\n\\ndef _bytes_feature(value):\\n    if isinstance(value, type(tf.constant(0))):\\n        value = value.numpy()\\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\\n\\ndef _float_feature(value):\\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\\n\\ndef _int64_feature(value):\\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\\n\\n\\n\\nfor i, file in enumerate(tqdm(normal_img_files)):\\n    img_path = os.path.join(camera0_dir, file)\\n    image = Image.open(img_path)\\n    image = image.resize((IMG_SIZE, IMG_SIZE))\\n    bimage = image.tobytes()\\n    \\n    example = tf.train.Example(features = tf.train.Features(feature = {\\n        'image':_bytes_feature(bimage),\\n        'cls_num':_int64_feature(0)\\n    }))\\n    if i < N_N_TRAIN:\\n        train_tfr_writer.write(example.SerializeToString())\\n    else:\\n        val_tfr_writer.write(example.SerializeToString())\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#학습 데이터를 용량이 적은 RAM 대신에 디스크에서 필요한 만큼 불러가면서 학습하기 위해 tfrecord를 사용함\n",
    "#학습 데이터 디스크에 저장 \n",
    "\n",
    "train_tfr_writer = tf.io.TFRecordWriter(train_tfr_dir)\n",
    "val_tfr_writer = tf.io.TFRecordWriter(val_tfr_dir)\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "\n",
    "for i, file in enumerate(tqdm(normal_img_files)):\n",
    "    img_path = os.path.join(camera0_dir, file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    bimage = image.tobytes()\n",
    "    \n",
    "    example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "        'image':_bytes_feature(bimage),\n",
    "        'cls_num':_int64_feature(0)\n",
    "    }))\n",
    "    if i < N_N_TRAIN:\n",
    "        train_tfr_writer.write(example.SerializeToString())\n",
    "    else:\n",
    "        val_tfr_writer.write(example.SerializeToString())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1622380138518,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "8e0y7dSklFj6",
    "outputId": "1caed77b-680d-4430-a950-392d7822006d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, file in enumerate(tqdm(fire_img_files)):\\n    img_path = os.path.join(camera1_dir,file)\\n    image = Image.open(img_path)\\n    image = image.resize((IMG_SIZE,IMG_SIZE))\\n    bimage = image.tobytes()\\n    \\n    example = tf.train.Example(features=tf.train.Features(feature={\\n        'image':_bytes_feature(bimage),\\n        'cls_num':_int64_feature(1)\\n    }))\\n    \\n    if i < N_F_TRAIN:\\n        train_tfr_writer.write(example.SerializeToString())\\n    else:\\n        val_tfr_writer.write(example.SerializeToString())\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "for i, file in enumerate(tqdm(fire_img_files)):\n",
    "    img_path = os.path.join(camera1_dir,file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE,IMG_SIZE))\n",
    "    bimage = image.tobytes()\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image':_bytes_feature(bimage),\n",
    "        'cls_num':_int64_feature(1)\n",
    "    }))\n",
    "    \n",
    "    if i < N_F_TRAIN:\n",
    "        train_tfr_writer.write(example.SerializeToString())\n",
    "    else:\n",
    "        val_tfr_writer.write(example.SerializeToString())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1622380138519,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "YfcGetGYlFKN",
    "outputId": "163582ce-bf42-4eba-fc38-127bacfc52c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i, file in enumerate(tqdm(smoke_img_files)):\\n    img_path = os.path.join(camera2_dir,file)\\n    image = Image.open(img_path)\\n    image = image.resize((IMG_SIZE,IMG_SIZE))\\n    bimage = image.tobytes()\\n    \\n    example = tf.train.Example(features=tf.train.Features(feature={\\n        'image':_bytes_feature(bimage),\\n        'cls_num':_int64_feature(2)\\n    }))\\n    \\n    if i < N_S_TRAIN:\\n        train_tfr_writer.write(example.SerializeToString())\\n    else:\\n        val_tfr_writer.write(example.SerializeToString())\\n        \\ntrain_tfr_writer.close()\\nval_tfr_writer.close()\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"for i, file in enumerate(tqdm(smoke_img_files)):\n",
    "    img_path = os.path.join(camera2_dir,file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE,IMG_SIZE))\n",
    "    bimage = image.tobytes()\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image':_bytes_feature(bimage),\n",
    "        'cls_num':_int64_feature(2)\n",
    "    }))\n",
    "    \n",
    "    if i < N_S_TRAIN:\n",
    "        train_tfr_writer.write(example.SerializeToString())\n",
    "    else:\n",
    "        val_tfr_writer.write(example.SerializeToString())\n",
    "        \n",
    "train_tfr_writer.close()\n",
    "val_tfr_writer.close()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1622380138522,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "-ksChT8cJ2aB"
   },
   "outputs": [],
   "source": [
    "#데이터 수 계산\n",
    "N_TRAIN = N_F_TRAIN+N_N_TRAIN+N_S_TRAIN #train 데이터의 총 개수\n",
    "N_VAL = N_F_VAL + N_N_VAL + N_S_VAL #vlaidation 데이터의 총 개수\n",
    "N_BATCH = 32 #batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1622380138978,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "aTi73ATnJ2aC"
   },
   "outputs": [],
   "source": [
    "#디스크에서 학습 데이터를 필요한 만큼 불러오는 인스턴스 생성\n",
    "def _parse_function(tfreced_serialized):\n",
    "    features = {\n",
    "        'image':tf.io.FixedLenFeature([],tf.string),\n",
    "        'cls_num':tf.io.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(tfreced_serialized,features)\n",
    "    \n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image,[IMG_SIZE,IMG_SIZE,3])\n",
    "    image = tf.cast(image,tf.float32)/255.\n",
    "    \n",
    "    cls_label = tf.cast(parsed_features['cls_num'],tf.int64)\n",
    "    \n",
    "    return image, cls_label\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_tfr_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(val_tfr_dir)\n",
    "val_dataset = val_dataset.map(_parse_function,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(N_BATCH).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1622380138981,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "hjGHspB4J2aC",
    "outputId": "2cb0009f-7a0f-4476-a8cf-b7f9052878e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#이미지가 잘 불러지고 있는지 확인\\n\\nfor image, label in train_dataset.take(10):\\n    if label[0].numpy()==1:\\n        plt.title('FIRE')\\n    elif label[0].numpy()==0:\\n        plt.title('NOT FIRE')\\n    else:\\n        plt.title('SMOKE')\\n    plt.imshow(image[0])\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#이미지가 잘 불러지고 있는지 확인\n",
    "\n",
    "for image, label in train_dataset.take(10):\n",
    "    if label[0].numpy()==1:\n",
    "        plt.title('FIRE')\n",
    "    elif label[0].numpy()==0:\n",
    "        plt.title('NOT FIRE')\n",
    "    else:\n",
    "        plt.title('SMOKE')\n",
    "    plt.imshow(image[0])\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J2uYOJCJ2aE"
   },
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "InceptionresnetV2 = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "#mobilenetv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1622380138984,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "KcMJYx30J2aE"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input([IMG_SIZE, IMG_SIZE, 3], dtype = tf.float32))\n",
    "    model.add(tf.keras.layers.Lambda(preprocess_input, name='preprocessing', input_shape=(224, 224, 3)))\n",
    "    model.add(InceptionresnetV2)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1622380139286,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "WRkWvRDRJ2aF",
    "outputId": "a6860385-c3f1-47cc-f456-f058c3a35a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "preprocessing (Lambda)       (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, 5, 5, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 4611      \n",
      "=================================================================\n",
      "Total params: 54,341,347\n",
      "Trainable params: 54,280,803\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1622380139288,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "rdwrgglWJ2aG"
   },
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 설정\n",
    "N_EPOCHS = 10\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = N_TRAIN/N_BATCH\n",
    "validation_step = int(np.ceil(N_VAL / N_BATCH))\n",
    "\n",
    "#오차 함수\n",
    "def loss_fn(y_true,y_pred):\n",
    "    return keras.losses.SparseCategoricalCrossentropy()(y_true,y_pred)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                         decay_steps=steps_per_epoch*2,\n",
    "                                                         decay_rate=0.5,\n",
    "                                                         staircase=True)\n",
    "model.compile(tf.keras.optimizers.RMSprop(lr_schedule),loss=loss_fn, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "executionInfo": {
     "elapsed": 451201,
     "status": "error",
     "timestamp": 1622380590479,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "LoH1x4oEJ2aG",
    "outputId": "78703c3d-b600-4559-b484-de0b51cfd699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 6909s 35s/step - loss: 0.3148 - accuracy: 0.8830 - val_loss: 2.1946 - val_accuracy: 0.6210\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 7662s 39s/step - loss: 0.0682 - accuracy: 0.9786 - val_loss: 1.8838 - val_accuracy: 0.6243\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 7478s 38s/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.7048 - val_accuracy: 0.8344\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 7726s 39s/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.5347 - val_accuracy: 0.8921\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 8272s 42s/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.5306 - val_accuracy: 0.9017\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 7329s 37s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.5331 - val_accuracy: 0.9036\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 6670s 34s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4522 - val_accuracy: 0.9160\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 6007s 31s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.4618 - val_accuracy: 0.9117\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 5438s 28s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4408 - val_accuracy: 0.9189\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 4891s 25s/step - loss: 1.4520e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9232\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "start = time.time()\n",
    "hist = model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n",
    "         epochs=N_EPOCHS,\n",
    "         validation_data=val_dataset,\n",
    "         validation_steps=validation_step)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1622380590474,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "zHmCbRAhJ2aG"
   },
   "outputs": [],
   "source": [
    "#모델 테스트\n",
    "test_dir = os.path.join(camera_dir,'test')\n",
    "test0_dir = os.path.join(test_dir,'0')\n",
    "test1_dir = os.path.join(test_dir,'1')\n",
    "test2_dir = os.path.join(test_dir,'2')\n",
    "test_normal_img_files = os.listdir(test0_dir)\n",
    "test_fire_img_files = os.listdir(test1_dir)\n",
    "test_smoke_img_files = os.listdir(test2_dir)\n",
    "test_x = []\n",
    "test_y = []\n",
    "for file in test_normal_img_files:\n",
    "    img_path = os.path.join(test0_dir,file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(np.array(image), tf.float32)/255.\n",
    "    test_x.append(image)\n",
    "    test_y.append(0)\n",
    "    \n",
    "for file in test_fire_img_files:\n",
    "    img_path = os.path.join(test1_dir,file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(np.array(image), tf.float32)/255.\n",
    "    test_x.append(image)\n",
    "    test_y.append(1)\n",
    "    \n",
    "for file in test_smoke_img_files:\n",
    "    img_path = os.path.join(test2_dir,file)\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(np.array(image), tf.float32)/255.\n",
    "    test_x.append(image)\n",
    "    test_y.append(2)\n",
    "    \n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1622380590476,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "qD8mJNmDJ2aH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamekey = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1622380590477,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "bFmIx4KWJ2aH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/Classification_Model1623235846\\assets\n"
     ]
    }
   ],
   "source": [
    "#모델 저장\n",
    "model.save('./model/Classification_Model{}'.format(filenamekey))\n",
    "model.save_weights('./model/Classification_Model_weights{}.h5'.format(filenamekey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1622380590477,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "B6_k7rJsJ2aH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 263s 11s/step - loss: 0.6494 - accuracy: 0.9080\n",
      "## evaluation loss and_metrics ##\n",
      "[0.6493809223175049, 0.9079999923706055]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(test_x, test_y, batch_size=N_BATCH)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1622380590478,
     "user": {
      "displayName": "김은란/컴퓨터공학전공/학생",
      "photoUrl": "",
      "userId": "12771623514668636348"
     },
     "user_tz": -540
    },
    "id": "yYJv5AQ3J2aH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig, loss_ax = plt.subplots()\n",
    "#acc_ax = loss_ax.twinx()\n",
    "\n",
    "#loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "#loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "#loss_ax.set_xlabel('epoch')\n",
    "#loss_ax.set_ylabel('loss')\n",
    "#loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.text(N_EPOCHS-1,loss_and_metrics[1], 'ta : {}'.format(format(loss_and_metrics[1],\".2f\")), fontsize=11, bbox=dict(boxstyle='square', color='lightgray'),horizontalalignment='right')\n",
    "\n",
    "plt.savefig('./result/graph/figure{}_{}.png'.format(data.shape[0],filenamekey))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/modelsummary{}.txt'.format(filenamekey), 'w') as f:\n",
    "\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.append({'key':filenamekey,\n",
    "                    'common train data len':N_N_TRAIN, \n",
    "                    \"fire train data len\":N_F_TRAIN,\n",
    "                    \"smoke train data len\":N_S_TRAIN, \n",
    "                    \"common validation data len\":N_N_VAL, \n",
    "                    \"fire validation data len\":N_F_VAL, \n",
    "                    \"smoke validation data len\":N_S_VAL,\n",
    "                    \"EPOCHS\":N_EPOCHS,\n",
    "                    \"learning_rate_schedule\":\"ExponentialDecay(initial_learning_rate={},decay_steps={},decay_rate=0.5,staircase=True)\".format(learning_rate,steps_per_epoch*2),\n",
    "                    \"batch size\":N_BATCH,\n",
    "                    \"loss_func\":'SparseCategoricalCrossentropy',\n",
    "                    \"optimizer\":\"RMSprop\",\n",
    "                    \"comment\": \"inception_resnet_v2\",\n",
    "                    \"test_accuracy\":loss_and_metrics[1],\n",
    "                    \"train time\":format(end-start, \".2f\")},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>common train data len</th>\n",
       "      <th>fire train data len</th>\n",
       "      <th>smoke train data len</th>\n",
       "      <th>common validation data len</th>\n",
       "      <th>fire validation data len</th>\n",
       "      <th>smoke validation data len</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>learning_rate_schedule</th>\n",
       "      <th>batch size</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>comment</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train time</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3900</td>\n",
       "      <td>1608</td>\n",
       "      <td>768</td>\n",
       "      <td>1301</td>\n",
       "      <td>537</td>\n",
       "      <td>257</td>\n",
       "      <td>10</td>\n",
       "      <td>ExponentialDecay(initial_learning_rate=0.0001,...</td>\n",
       "      <td>32</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>단순 CNN 네트워크로 구성된 모델</td>\n",
       "      <td>0.797333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3900</td>\n",
       "      <td>3216</td>\n",
       "      <td>3075</td>\n",
       "      <td>1301</td>\n",
       "      <td>1074</td>\n",
       "      <td>1025</td>\n",
       "      <td>10</td>\n",
       "      <td>ExponentialDecay(initial_learning_rate=0.0001,...</td>\n",
       "      <td>32</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>데이터 증강</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3900</td>\n",
       "      <td>1608</td>\n",
       "      <td>768</td>\n",
       "      <td>1301</td>\n",
       "      <td>537</td>\n",
       "      <td>257</td>\n",
       "      <td>10</td>\n",
       "      <td>ExponentialDecay(initial_learning_rate=0.0001,...</td>\n",
       "      <td>32</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>단순+데이터증강+배치정규화</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>68382.69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3900</td>\n",
       "      <td>1608</td>\n",
       "      <td>768</td>\n",
       "      <td>1301</td>\n",
       "      <td>537</td>\n",
       "      <td>257</td>\n",
       "      <td>10</td>\n",
       "      <td>ExponentialDecay(initial_learning_rate=0.0001,...</td>\n",
       "      <td>32</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>inception_resnet_v2</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>68382.69</td>\n",
       "      <td>1.623236e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  common train data len  fire train data len  \\\n",
       "0         0.0           0.0                   3900                 1608   \n",
       "1         1.0           NaN                   3900                 3216   \n",
       "2         NaN           NaN                   3900                 1608   \n",
       "3         NaN           NaN                   3900                 1608   \n",
       "\n",
       "   smoke train data len  common validation data len  fire validation data len  \\\n",
       "0                   768                        1301                       537   \n",
       "1                  3075                        1301                      1074   \n",
       "2                   768                        1301                       537   \n",
       "3                   768                        1301                       537   \n",
       "\n",
       "   smoke validation data len  EPOCHS  \\\n",
       "0                        257      10   \n",
       "1                       1025      10   \n",
       "2                        257      10   \n",
       "3                        257      10   \n",
       "\n",
       "                              learning_rate_schedule  batch size  \\\n",
       "0  ExponentialDecay(initial_learning_rate=0.0001,...          32   \n",
       "1  ExponentialDecay(initial_learning_rate=0.0001,...          32   \n",
       "2  ExponentialDecay(initial_learning_rate=0.0001,...          32   \n",
       "3  ExponentialDecay(initial_learning_rate=0.0001,...          32   \n",
       "\n",
       "                       loss_func optimizer              comment  \\\n",
       "0  SparseCategoricalCrossentropy   RMSprop  단순 CNN 네트워크로 구성된 모델   \n",
       "1  SparseCategoricalCrossentropy   RMSprop               데이터 증강   \n",
       "2  SparseCategoricalCrossentropy   RMSprop       단순+데이터증강+배치정규화   \n",
       "3  SparseCategoricalCrossentropy   RMSprop  inception_resnet_v2   \n",
       "\n",
       "   test_accuracy train time           key  \n",
       "0       0.797333        NaN           NaN  \n",
       "1       0.664000        NaN           NaN  \n",
       "2       0.908000   68382.69           NaN  \n",
       "3       0.908000   68382.69  1.623236e+09  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./result/HyperParameter.csv',encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fire Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
