{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Localization Model의 오차함수 \n",
    "def local_loss_fn(y_true,y_pred):\n",
    "    return keras.losses.MeanSquaredError()(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Model의 오차함수\n",
    "def class_loss_fn(y_true,y_pred):\n",
    "    return keras.losses.SparseCategoricalCrossentropy()(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localization + Classification Model\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.classification = tf.keras.models.load_model(\"./model/Classification_Model1623163568\",custom_objects={'loss_fn': local_loss_fn})\n",
    "        self.classification.load_weights('./model/Classification_Model_weights1623163568.h5')\n",
    "        self.localization = tf.keras.models.load_model(\"./model/Localization_Model\",custom_objects={'loss_fn': class_loss_fn})\n",
    "        self.localization.load_weights('./model/Localization_Model_weights.h5')\n",
    "        self.con = tf.keras.layers.Concatenate(axis=-1)\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        a = self.classification(x)\n",
    "        b = self.localization(x)\n",
    "    \n",
    "        return self.con([a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 640\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data/video/CCTV/fire and smoke.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(height, width)\n",
    "i=0\n",
    "SPEED = 10#영상 재생 속도\n",
    "while True: \n",
    "    if cap.grab():\n",
    "        ret, frame = cap.retrieve()\n",
    "        i+=1\n",
    "        if i%SPEED != 0:\n",
    "            continue\n",
    "        if ret:\n",
    "            #영상을 읽어서 모델에 입력할 수 있도록 자료형 변환\n",
    "            frame2 = cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "            image = Image.fromarray(frame2)\n",
    "            image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "            image = tf.cast(np.array(image), tf.float32)/255.\n",
    "            image = image[tf.newaxis,...]\n",
    "            \n",
    "            #영상 인식\n",
    "            prediction = model.predict(image)\n",
    "            pred_label = int(tf.argmax(prediction[0][:3]))\n",
    "            pred_local = prediction[0][3:]\n",
    "            \n",
    "            #원본 영상에 인식결과 합성\n",
    "            if pred_label==0:\n",
    "                frame = cv2.rectangle(frame,(0,0),(150,40),(255,255,255),cv2.FILLED)\n",
    "                frame=cv2.putText(frame,\"Non-Fire\", (0, 30), cv2.FONT_ITALIC, 1, (0, 0, 255),3)\n",
    "            elif pred_label == 1:\n",
    "                frame = cv2.rectangle(frame,(0,0),(80,40),(255,255,255),cv2.FILLED)\n",
    "                frame=cv2.putText(frame,\"Fire!!\", (0, 30), cv2.FONT_ITALIC, 1, (0, 0, 255),3)\n",
    "                pred_x = pred_local[0]\n",
    "                pred_y = pred_local[1]\n",
    "                pred_w = pred_local[2]\n",
    "                pred_h = pred_local[3]\n",
    "            \n",
    "                pred_xmin = int((pred_x - pred_w/2.)*cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                pred_ymin = int((pred_y - pred_h/2.)*cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                pred_xmax = int((pred_x + pred_w/2.)*cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                pred_ymax = int((pred_y + pred_h/2.)*cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "                frame = cv2.rectangle(frame,(pred_xmin,pred_ymin),(pred_xmax,pred_ymax),(0,0,255),2)\n",
    "\n",
    "            elif pred_label== 2:\n",
    "                frame = cv2.rectangle(frame,(0,0),(120,40),(255,255,255),cv2.FILLED)\n",
    "                frame=cv2.putText(frame,\"SMOKE!\", (0, 30), cv2.FONT_ITALIC, 1, (0, 0, 255),3)\n",
    "            \n",
    "            #합성 영상 출력\n",
    "            cv2.imshow('video', frame)\n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            if k == 27:\n",
    "                cap.release()\n",
    "                cv2.destroyWindow('video')\n",
    "                break\n",
    "        else:\n",
    "            print('error')\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "#영상 출력 윈도우 제거\n",
    "if cv2.getWindowProperty('video',0) != -1:\n",
    "    cap.release()\n",
    "    cv2.destroyWindow('video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2374\u001b[0m     \"\"\"\n\u001b[0;32m   2375\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2376\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2377\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2378\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
